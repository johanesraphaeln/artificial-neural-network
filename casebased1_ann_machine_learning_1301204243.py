# -*- coding: utf-8 -*-
"""CaseBased1 ANN - Machine Learning - 1301204243

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lUn4xSF4x7Wz6NaGV9wUgQ4gOZ4HGliy
"""

# import library
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.pyplot as mp
import seaborn as sns
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# import dataset
dataset = pd.read_csv(
    'https://github.com/johanesraphaeln/case-based-1-supervised-learning/blob/main/dataset/audit_risk.csv?raw=true'
    )
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

# tabel dataset keseluruhan
dataset

# 5 data teratas
dataset.head()

# 5 data terbawah
dataset.tail()

# size dataset
dataset.shape

# statistik deskriptif
dataset.describe()

# korelasi
corr = dataset.corr()
corr

# korelasi berbentuk heatmap
mp.subplots(figsize=(20,20))
sns.heatmap(dataset.corr(), cmap="YlGnBu", annot=True, square=True)

sns.boxplot(dataset['Score'])

# cek outliers
def find_outliers_IQR(df):
   q1=df.quantile(0.25)
   q3=df.quantile(0.75)
   IQR=q3-q1
   outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]
   return outliers

print(find_outliers_IQR(dataset['Score']))

# mendrop row outliers berada
dataset = dataset.drop([93, 190, 241, 495])

# mencari missing value
dataset.isnull().sum()

# menghilangkan row dari missing value
dataset = dataset.dropna()

dataset.duplicated().sum()

dataset.loc[dataset.duplicated(), :]

# menghilangkan data redundant
dataset = dataset.drop_duplicates()

dataset.shape

# split dataset
X = dataset.iloc[:, 2:26].values
Y = dataset.iloc[:, -1].values
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)

# feature scaling
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

# init ANN
ann = tf.keras.models.Sequential()

# first hidden layer
ann.add(tf.keras.layers.Dense(
    units=6,
    activation="relu"
))

# second hidden layer
ann.add(tf.keras.layers.Dense(
    units=6,
    activation="relu"
))

# output layer
ann.add(tf.keras.layers.Dense(
    units=1,
    activation="sigmoid"
))

# compile ANN
ann.compile(
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=['accuracy']
)

# fitting ANN
ann.fit(
    X_train,
    Y_train,
    batch_size = 32,
    epochs = 100
)

Y_predict = ann.predict(X_test)
Y_predict = (Y_predict > 0.5)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(Y_test, Y_predict)
cm

from sklearn.metrics import classification_report
print(classification_report(Y_test, Y_predict))

